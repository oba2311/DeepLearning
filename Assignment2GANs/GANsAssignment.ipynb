{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 497, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/usr/local/miniconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# dependencies:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12bd344e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load MNIST:\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "# \n",
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "# the shape is a row on 784:\n",
    "print(sample_image.shape)\n",
    "#%% \n",
    "\n",
    "\n",
    "#%% \n",
    "# standadize the image size and take a look:\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "# imshow will visuzliae the scalar 2D images once those are reshaped from 784X1\n",
    "# to 28X28:\n",
    "plt.imshow(sample_image, cmap='Greys')\n",
    "#%% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:\n",
    "# D is a classic feedforward CNN. This network is built from two convolutional\n",
    "#  layers and two fully connected layers. Pooling is used:\n",
    "\n",
    "def discriminator(images, reuse=False):\n",
    "    if (reuse):\n",
    "        # reuse=tf.AUTO_REUSE\n",
    "        # The function reuse_variables() will always produce None as a result. \n",
    "        # Its only function is to set the attribute reuse of the current scope to True.\n",
    "        # get_variable_scope() returns current variable scope.\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    # First convolutional and pool layers\n",
    "    # This finds 32 different 5 x 5 pixel features\n",
    "    # initializer=tf.truncated_normal_initializer: Initializer that generates a truncated normal distribution:\n",
    "    # get_variable either creates or gets the required variable:\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    # as far as I can tell, choosing stddev here is tuning more than hard code science.\n",
    "    # Initializer that generates tensors with constant values for the bias:\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    # tf.nn.conv2d  - Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # adding the bias:\n",
    "    d1 = d1 + d_b1\n",
    "    # activation:\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    # Performs the average pooling on the input:\n",
    "    # average pooling takes the average of the pixels within the window defined:\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # This finds 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    # matmul = matrix multiplication:\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "    # d4 contains unscaled values\n",
    "    print(\"finished with D\")\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D has been defined!\n"
     ]
    }
   ],
   "source": [
    "print(\"D has been defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G:\n",
    "def generator(z, batch_size, z_dim):\n",
    "    # takes random values, the batchsize and zdim would be the numver of coloumns.\n",
    "    # batch_size is essentially the number of images produced.\n",
    "    # z_dim is num of random values per image produced.\n",
    "    # first layer takes noise + vlaues, batchnorm and ReLus:\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # the rest is 3 convolutions, which will flash out high-level features:\n",
    "\n",
    "    # Generate 50 features\n",
    "    # second layer  - convolutions:\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    # batchnorm:\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    # scale back to original size:\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    # turning back to original size:\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    # squeeze values either way (i.e. pixels to be black or white)\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G has been defined!\n"
     ]
    }
   ],
   "source": [
    "print(\"G has been defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "# initiate a placeholder with random values:\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "#%% \n",
    "\n",
    "#%% \n",
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "# initiate a matrix with random values:\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])\n",
    "#%% \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test G: generate a random image:\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                                feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholders defined!\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "print(\"placeholders defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-78d37757f41c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreuse\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder) \n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "# with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "#     pass \n",
    "\n",
    "# with tf.variable_scope(tf.get_variable_scope()) as vscope:\n",
    "#     tf.get_variable_scope().reuse_variables()     # HERE\n",
    "\n",
    "# with tf.variable_scope(\"discriminator\") as scope:\n",
    "#     scope.reuse_variables()\n",
    "\n",
    "# with tf.variable_scope(\"generator\") as scope: \n",
    "#     scope.reuse_variables()\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "    assert tf.get_variable_scope().reuse == True\n",
    "\n",
    "\n",
    "\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss funcs for D:\n",
    "# cross entropy loss\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Dx, logits=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Dg, logits=tf.zeros_like(Dg)))\n",
    "#%% \n",
    "\n",
    "\n",
    "#%% \n",
    "# loss for the generator:\n",
    "# the loss is of course the opposite to the d_loss_fake since it's a minmax game (g is maximizing \n",
    "# what d is trying to minimize, i.e. fake pics classified as real).\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Dg, logits=tf.ones_like(Dg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_w2:0', 'g_b2:0', 'g_w3:0', 'g_b3:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable d_w1/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f9160e4cec17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tf.train.AdamOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0md_trainer_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0md_trainer_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n\u001b[0;32m--> 365\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   def compute_gradients(self, loss, var_list=None,\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, global_step, name)\u001b[0m\n\u001b[1;32m    514\u001b[0m                        ([str(v) for _, _, v in converted_grads_and_vars],))\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_slots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_get_variable_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/adam.py\u001b[0m in \u001b[0;36m_create_slots\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# Create slots for the first and second moments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"v\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36m_zeros_slot\u001b[0;34m(self, var, slot_name, op_name)\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0mnamed_slots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamed_slots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m       \u001b[0mnamed_slots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslot_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_zeros_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnamed_slots\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36mcreate_zeros_slot\u001b[0;34m(primary, name, dtype, colocate_with_primary)\u001b[0m\n\u001b[1;32m    172\u001b[0m     return create_slot_with_initializer(\n\u001b[1;32m    173\u001b[0m         \u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         colocate_with_primary=colocate_with_primary)\n\u001b[0m\u001b[1;32m    175\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36mcreate_slot_with_initializer\u001b[0;34m(primary, initializer, shape, dtype, name, colocate_with_primary)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n\u001b[0;32m--> 148\u001b[0;31m                                 dtype)\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       return _create_slot_var(primary, initializer, \"\", validate_shape, shape,\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/training/slot_creator.py\u001b[0m in \u001b[0;36m_create_slot_var\u001b[0;34m(primary, val, scope, validate_shape, shape, dtype)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_is_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_partitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_partitioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1263\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1264\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1095\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    433\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    759\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    760\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable d_w1/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "# Train the discriminator\n",
    "# tf.train.AdamOptimizer\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable g_b1/beta does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9fda16d3d0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# x_placeholder is for feeding input images to the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mGz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;31m# Gz holds the generated images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-9fda16d3d0bd>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(batch_size, z_dim)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_w1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mg_b1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g_b1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, param_regularizers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope, renorm, renorm_clipping, renorm_decay, adjustment)\u001b[0m\n\u001b[1;32m    665\u001b[0m           \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m           fused=fused)\n\u001b[0;32m--> 667\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m               \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m           \u001b[0;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    290\u001b[0m           \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m           trainable=True)\n\u001b[0m\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[1;32m    502\u001b[0m                                    \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                                    \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                                    partitioner=partitioner)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           if (trainable and self.trainable\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1263\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1264\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1095\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"constraint\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **_)\u001b[0m\n\u001b[1;32m   1557\u001b[0m       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m       \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m       custom_getter=getter, use_resource=use_resource)\n\u001b[0m\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    289\u001b[0m                  \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                  \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                  use_resource=use_resource)\n\u001b[0m\u001b[1;32m    292\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    244\u001b[0m                   \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                   \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                   use_resource=use_resource)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    759\u001b[0m       raise ValueError(\"Variable %s does not exist, or was not created with \"\n\u001b[1;32m    760\u001b[0m                        \u001b[0;34m\"tf.get_variable(). Did you mean to set \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                        \"reuse=tf.AUTO_REUSE in VarScope?\" % name)\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minitializing_from_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m       raise ValueError(\"Shape of a new variable (%s) must be fully defined, \"\n",
      "\u001b[0;31mValueError\u001b[0m: Variable g_b1/beta does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a straightforward Python implementation of a generative adversarial network.\n",
    "The code is derived from the O'Reilly interactive tutorial on GANs\n",
    "(https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners).\n",
    "The tutorial's code trades efficiency for clarity in explaining how GANs function;\n",
    "this script refactors a few things to improve performance, especially on GPU machines.\n",
    "In particular, it uses a TensorFlow operation to generate random z values and pass them\n",
    "to the generator; this way, more computations are contained entirely within the\n",
    "TensorFlow graph.\n",
    "A version of this model with explanatory notes is also available on GitHub\n",
    "at https://github.com/jonbruner/generative-adversarial-networks.\n",
    "This script requires TensorFlow and its dependencies in order to run. Please see\n",
    "the readme for guidance on installing TensorFlow.\n",
    "This script won't print summary statistics in the terminal during training;\n",
    "track progress and see sample images in TensorBoard.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "# Load MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "# Define the discriminator network\n",
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        # d4 contains unscaled values\n",
    "        return d4\n",
    "\n",
    "# Define the generator network\n",
    "def generator(batch_size, z_dim):\n",
    "    z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1, name='z')\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='g_b1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='g_b2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='g_b3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4\n",
    "\n",
    "z_dimensions = 100\n",
    "batch_size = 50\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder')\n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(batch_size, z_dimensions)\n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images\n",
    "\n",
    "# Define losses\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))\n",
    "\n",
    "# Define variable lists\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Define the optimizers\n",
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GANs",
   "language": "python",
   "name": "gans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
