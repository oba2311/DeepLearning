{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 25)\n",
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data prep:\n",
    "TRAINPATH = \"/Users/a8407352/Desktop/deepLearn/datasets/titanic/trainingReady.csv\"\n",
    "TRAINLABELSPATH = \"/Users/a8407352/Desktop/deepLearn/datasets/titanic/TrainLabelsReady.csv\"\n",
    "TESTPATH = \"/Users/a8407352/Desktop/deepLearn/datasets/titanic/testReady.csv\"\n",
    "\n",
    "# training data:\n",
    "train = pd.read_csv(TRAINPATH)\n",
    "train = train.drop(columns=\"Unnamed: 0\")\n",
    "print(train.shape)\n",
    "\n",
    "# labels:\n",
    "trainLabels = pd.read_csv(TRAINLABELSPATH)\n",
    "trainLabels = trainLabels.drop(columns= trainLabels.columns[0])\n",
    "trainLabels.head()\n",
    "\n",
    "print(trainLabels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, trainLabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n"
     ]
    }
   ],
   "source": [
    "class NN:\n",
    "    def __init__(self):\n",
    "#         11 features:\n",
    "        self.inputSize = X_train.transpose().shape[1]\n",
    "\n",
    "N=NN()\n",
    "print(N.inputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         arbitrary numbers chosen:\n",
    "        self.hiddenSize = 20\n",
    "        self.hiddenSize2 = 13\n",
    "#         binary classification:\n",
    "        self.outputSize = 1\n",
    "\n",
    "#         define weights:\n",
    "        self.W1 = np.zeros((self.inputSize, self.hiddenSize))\n",
    "        self.W2 = np.zeros((self.hiddenSize2, self.hiddenSize))\n",
    "        self.W3 = np.zeros((self.outputSize, self.hiddenSize2))\n",
    "        \n",
    "#         Activation funcs:\n",
    "    def sigmoid(x):\n",
    "        squashedNum = 1/(1+np.exp(-x))\n",
    "        return squashedNum\n",
    "\n",
    "    \n",
    "    def ReLu(x):\n",
    "        return np.max([0,x])\n",
    "\n",
    "    vectorizedReLu = np.vectorize(ReLu)\n",
    "    \n",
    "    def forwardPass(self, inputt):\n",
    "        print(inputt)\n",
    "#     multiply input layer and its corresponding weights (biass could be added):\n",
    "        inputXWeights = np.dot(self.W1,inputt)\n",
    "#     activation1:\n",
    "        act1 = sigmoid(inputXWeights) \n",
    "#     multiply hidden layer and its corresponding weights:\n",
    "        inputXWeights2 = np.dot(self.W2,act1)\n",
    "#     activation2:\n",
    "        act2 = self.sigmoid(inputXWeights2)\n",
    "    \n",
    "        inputXWeights3 = np.dot(self.W3,act2)\n",
    "        act3 = self.sigmoid(inputXWeights3)\n",
    "        print(act3)\n",
    "        return act3\n",
    "    \n",
    "NN=NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(NN.inputSize)\n",
    "print(NN.W1.shape)\n",
    "print(X_train.transpose().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def dSig(x):    \n",
    "        derivResult = sigmoid(x) *(1-sigmoid(x))\n",
    "        return derivResult\n",
    "    \n",
    "    \n",
    "    def dReLu(x):\n",
    "        if x <= 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "\n",
    "    vectorizedDerReLu = np.vectorize(dReLu)\n",
    "    \n",
    "    #     Loss func:\n",
    "# adopted from:\n",
    "# https://stackoverflow.com/questions/49473587/how-to-compute-log-loss-same-as-cross-entropy\n",
    "    def cross_entropy(predictions, trainLables):\n",
    "        N = predictions.shape[0]\n",
    "        ce = -np.sum(targets*np.log(predictions))/N\n",
    "        return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(y_hat):\n",
    "    weights = []\n",
    "#     derivative of the correct label with respect to the classification:\n",
    "\n",
    "    weights.add(adopted_weights)\n",
    "#     derivative of the classification with respect to the weights:\n",
    "\n",
    "    weights.add(adopted_weights)\n",
    "#     derivative of the classification with respect to the weights:\n",
    "\n",
    "    weights.add(adopted_weights)\n",
    "#     derivative of the classification with respect to the weights:\n",
    "\n",
    "    weights.add(adopted_weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainLoop(X_train, y_train):\n",
    "    NN.forwardPass(X_train)\n",
    "    \n",
    "trainLoop(X_train.transpose(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to implement:\n",
    "1. the forward calculation\n",
    "2. the gradient calculation\n",
    "3. updating the weights\n",
    "\n",
    "And then show that your implementation can indeed learn to predict the survival rate.  To show this, please plot the performance of an appropriate metric (eg. log-loss or accuracy) as training proceeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the concept of regularization in your network. Regularization can take many forms.  Some common ones include: i) weight decay during training.  ii) a dropout layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
